{
 "cells": [
  {
   "cell_type": "code",
   "id": "25d69a7d-5f0e-453a-8a7d-8ef4b100e72b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34608fe0-9c89-4b39-b0b7-59d74efafdbe",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import onnx\n",
    "import torch\n",
    "\n",
    "from finetune.segment.pskelp_model import PSKelpSegmentor\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8873272f-89e7-48de-9115-7c9d21b62c1f",
   "metadata": {},
   "source": [
    "### Define paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea85c6-5086-42b2-b032-489890554d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = (\n",
    "    \"../../checkpoints/segment/kelp-3class-segment_epoch-94_val-iou-0.7686.ckpt\"\n",
    ")\n",
    "CLAY_CHECKPOINT_PATH = \"../../checkpoints/clay-v1.5.ckpt\"\n",
    "METADATA_PATH = \"../../configs/metadata.yaml\"\n",
    "OUTPUT_PATH_ONNX = \"../../checkpoints/segment/kelp-1class-segment_epoch-94_val-iou-0.7686-deepness.onnx\"\n",
    "\n",
    "TRAIN_CHIP_DIR = \"../../data/cvpr/ny/train/chips/\"\n",
    "TRAIN_LABEL_DIR = \"../../data/cvpr/ny/train/labels/\"\n",
    "VAL_CHIP_DIR = \"../../data/cvpr/ny/val/chips/\"\n",
    "VAL_LABEL_DIR = \"../../data/cvpr/ny/val/labels/\"\n",
    "TILE_SIZE = 224\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "NUM_BANDS = 8\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 1\n",
    "PLATFORM = \"planetscope-sr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc278db5-e241-4763-8f33-bdeb5b0f81fc",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0da577-f3e5-485a-bbc5-a3ff7367e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(chesapeake_checkpoint_path, clay_checkpoint_path, metadata_path):\n",
    "    model = PSKelpSegmentor.load_from_checkpoint(\n",
    "        checkpoint_path=chesapeake_checkpoint_path,\n",
    "        metadata_path=metadata_path,\n",
    "        ckpt_path=clay_checkpoint_path,\n",
    "    )\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "id": "30d9b66b-ea25-4697-83be-776abb40db9b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Load model\n",
    "model = get_model(CHECKPOINT_PATH, CLAY_CHECKPOINT_PATH, METADATA_PATH).to(DEVICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Export model to ONNX\n",
   "id": "bf2b8b4ccb710b8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define dynamic axes for input and output\n",
    "dynamic_axes = {\n",
    "    \"input\": {\n",
    "        0: \"batch_size\",\n",
    "        # 2: \"tile_size\",\n",
    "        # 3: \"tile_size\",\n",
    "    },  # Dynamic batch size, height and width\n",
    "    \"output\": {\n",
    "        0: \"batch_size\",\n",
    "        # 2: \"tile_size\",\n",
    "        # 3: \"tile_size\",\n",
    "    },  # Dynamic batch size, height and width\n",
    "}\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "waves = torch.tensor(\n",
    "    [0.443, 0.490, 0.531, 0.565, 0.610, 0.665, 0.705, 0.865]\n",
    ")  # Planet SR wavelengths\n",
    "gsd = torch.tensor(5.0)  # Planet SR GSD\n",
    "\n",
    "\n",
    "class DeepnessModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(DeepnessModel, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = x.shape[0]\n",
    "\n",
    "        datacube = {\n",
    "            \"pixels\": x,\n",
    "            \"time\": torch.zeros((b, 4)),  # Placeholder for time information\n",
    "            \"latlon\": torch.zeros((b, 4)),  # Placeholder for latlon information\n",
    "            \"waves\": waves,\n",
    "            \"gsd\": gsd,\n",
    "        }\n",
    "        logits = self.model(datacube)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        # Convert class 1 probabilities to 2 class probs shape: # [batch_size, 2, height, width]\n",
    "        probs = torch.cat(\n",
    "            [\n",
    "                1 - probs,  # Background class\n",
    "                probs,  # Kelp class\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        return probs\n",
    "\n",
    "\n",
    "model = DeepnessModel(model.model).to(DEVICE)\n",
    "\n",
    "x = torch.rand(\n",
    "    1,\n",
    "    NUM_BANDS,\n",
    "    TILE_SIZE,\n",
    "    TILE_SIZE,\n",
    "    device=DEVICE,\n",
    "    requires_grad=False,\n",
    ")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,  # Model to export\n",
    "    x,  # Example input\n",
    "    OUTPUT_PATH_ONNX,  # Output file path\n",
    "    export_params=True,  # Store model weights in the model file\n",
    "    opset_version=14,  # ONNX opset version\n",
    "    do_constant_folding=True,  # Optimize constants\n",
    "    input_names=input_names,  # Input tensor names\n",
    "    output_names=output_names,  # Output tensor names\n",
    "    dynamic_axes=dynamic_axes,  # Dynamic axes specification\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "onnx_model = onnx.load(OUTPUT_PATH_ONNX)\n",
    "\n",
    "class_names = {\n",
    "    0: \"water\",\n",
    "    1: \"kelp\",\n",
    "    2: \"land\",\n",
    "}\n",
    "\n",
    "m1 = onnx_model.metadata_props.add()\n",
    "m1.key = \"model_type\"\n",
    "m1.value = json.dumps(\"Segmentor\")\n",
    "\n",
    "m2 = onnx_model.metadata_props.add()\n",
    "m2.key = \"class_names\"\n",
    "m2.value = json.dumps(class_names)\n",
    "\n",
    "m3 = onnx_model.metadata_props.add()\n",
    "m3.key = \"resolution\"\n",
    "m3.value = json.dumps(300)  # cm/px\n",
    "\n",
    "m4 = onnx_model.metadata_props.add()\n",
    "m4.key = \"tiles_overlap\"\n",
    "m4.value = json.dumps(40)  # 40% overlap\n",
    "\n",
    "m5 = onnx_model.metadata_props.add()\n",
    "m5.key = \"standardization_mean\"\n",
    "m5.value = json.dumps([v / 255. for v in [1720., 1715., 1913., 2088., 2274., 2290., 2613., 3970.]])\n",
    "\n",
    "m6 = onnx_model.metadata_props.add()\n",
    "m6.key = \"standardization_std\"\n",
    "m6.value = json.dumps([v / 255. for v in [747., 698., 739., 768., 849., 868., 849., 914.]])\n",
    "\n",
    "onnx.save(onnx_model, OUTPUT_PATH_ONNX)\n",
    "onnx.checker.check_model(onnx_model)"
   ],
   "id": "226d36afeab98e2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
